{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kT_o0a715tV6"
   },
   "source": [
    "# GPUデバイスの確認\n",
    "最新のTesla T4で無理なのでたぶん無理、諦めろ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4942,
     "status": "ok",
     "timestamp": 1581167459230,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "KtRiSptF7JAp",
    "outputId": "fbd72b97-0888-4f80-ce6c-2f7fb8fd7274"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1630,
     "status": "ok",
     "timestamp": 1581167487888,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "15WpRvou1Ysu",
    "outputId": "d44d061e-a050-48c1-c1ae-b9a90cd4fb6b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7pb2c9U1FFN"
   },
   "source": [
    "# 準備\n",
    "## 乾研のBERT用にMecabのインストール\n",
    "## hugging_faceのtransformersなどのpythonパッケージインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73192,
     "status": "ok",
     "timestamp": 1581167562424,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "Gs8OHARS3UtU",
    "outputId": "466714f6-f87c-446f-87cf-abc931c44b1a"
   },
   "outputs": [],
   "source": [
    "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab\n",
    "\n",
    "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
    "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n\n",
    "\n",
    "!sed -e \"s!/var/lib/mecab/dic/debian!/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd!g\" /etc/mecabrc > /etc/mecabrc.new\n",
    "\n",
    "!cp /etc/mecabrc /etc/mecabrc.org\n",
    "!cp /etc/mecabrc.new /etc/mecabrc\n",
    "\n",
    "!apt-get -q -y install swig\n",
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78090,
     "status": "ok",
     "timestamp": 1581167567666,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "UIUqaF0g1VDX",
    "outputId": "45268ca2-7ec7-48ad-8cdb-f8fac830ac4f"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-transformers transformers torchtext nltk neologdn emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7lgHsZJ1FFk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import string\n",
    "import re\n",
    "\n",
    "from torchtext.vocab import Vectors\n",
    "from pytorch_transformers import BertModel, BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n5pLmPf51FGc"
   },
   "source": [
    "# hugging_faceのtransformersより日本語BERTの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQ76BNv_1FGn"
   },
   "outputs": [],
   "source": [
    "bert = 'bert-base-japanese-whole-word-masking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88151,
     "status": "ok",
     "timestamp": 1581167578531,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "NXQtWrDK1FHH",
    "outputId": "57b1403f-ef3b-40b2-fd53-2092238cae7c"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(bert, num_labels=9)\n",
    "model.to(device)\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88602,
     "status": "ok",
     "timestamp": 1581167579183,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "MzUUENAp1FHg",
    "outputId": "9b92b1cc-6cde-4fde-81a3-ec0aa3504531"
   },
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "tokenizer.tokenize('お腹が痛いので遅れます。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVJBxspP1FHz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvEbujpr1FID"
   },
   "source": [
    "# livedoorニュースコーパス取得\n",
    "## pandasで読み込んで、使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103675,
     "status": "ok",
     "timestamp": 1581167594905,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "AL5LHcOO19Iy",
    "outputId": "1afec652-a5f6-4ef2-99f7-5ce0676a4777"
   },
   "outputs": [],
   "source": [
    "!mkdir dataset\n",
    "!cd dataset\n",
    "!wget https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
    "!tar zxvf ldcc-20140209.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYKRFTb02LzF"
   },
   "outputs": [],
   "source": [
    "!echo -e \"filename\\ttitle\\tarticle\\tlabel\" > ./text/livedoor.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jh1Y3Zeb2Op3"
   },
   "outputs": [],
   "source": [
    "!for filename in `basename -a ./text/dokujo-tsushin/dokujo-tsushin-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/dokujo-tsushin/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/dokujo-tsushin/$filename`; echo -e \"\\t1\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/it-life-hack/it-life-hack-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/it-life-hack/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/it-life-hack/$filename`; echo -e \"\\t2\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/kaden-channel/kaden-channel-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/kaden-channel/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/kaden-channel/$filename`; echo -e \"\\t3\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/livedoor-homme/livedoor-homme-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/livedoor-homme/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/livedoor-homme/$filename`; echo -e \"\\t4\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/movie-enter/movie-enter-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/movie-enter/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/movie-enter/$filename`; echo -e \"\\t5\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/peachy/peachy-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/peachy/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/peachy/$filename`; echo -e \"\\t6\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/smax/smax-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/smax/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/smax/$filename`; echo -e \"\\t7\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/sports-watch/sports-watch-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/sports-watch/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/sports-watch/$filename`; echo -e \"\\t8\"; done >> ./text/livedoor.tsv\n",
    "!for filename in `basename -a ./text/topic-news/topic-news-*`; do echo -n \"$filename\"; echo -ne \"\\t\"; echo -n `sed -n '3p' ./text/topic-news/$filename`; echo -ne \"\\t\"; echo -n `sed -e '1,3d' ./text/topic-news/$filename`; echo -e \"\\t9\"; done >> ./text/livedoor.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 178628,
     "status": "ok",
     "timestamp": 1581167670519,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "PbhbXKUs2nWc",
    "outputId": "0a757cf1-002b-40bb-fffb-232672521b0a"
   },
   "outputs": [],
   "source": [
    "mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qzvD_DqQ2rgA"
   },
   "source": [
    "# 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ow8xMmWJ1FIJ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./text/livedoor.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 177520,
     "status": "ok",
     "timestamp": 1581167670525,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "dXxrGq_x1FIV",
    "outputId": "b24f9b5c-bfc5-419f-ba6f-cb3fd3854b62"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiQXQ0Io1FIn"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qITTuAsU1FI2"
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XoDBCnQA1FJE"
   },
   "outputs": [],
   "source": [
    "# 扱えるテキストの量が128までだからtitle安定\n",
    "# articleでもいいけど、入力からされないのがある\n",
    "train = train[['title', 'label']]\n",
    "val = val[['title', 'label']]\n",
    "test = test[['title', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2oIQO7z1FJU"
   },
   "outputs": [],
   "source": [
    "train.to_csv('data/train.tsv', sep='\\t', index=False)\n",
    "val.to_csv('data/val.tsv', sep='\\t', index=False)\n",
    "test.to_csv('data/test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_j63etA1FJi"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import neologdn\n",
    "import unicodedata\n",
    "import emoji\n",
    "\n",
    "def cleaning(sentence):\n",
    "    symbols = (\"◆□■△▲▽▼※〒→←↑↓〓∈∋⊆⊇⊂⊃∪∩∧∨￢⇒⇔∀∃∠⊥\"\n",
    "                   \"⌒∂∇≡≒≪≫√∽∝∵∫∬Å‰♯♭♪†‡¶◯①②③④⑤⑥⑦⑧⑨\"\n",
    "                   \"⑩⑪⑫⑬⑭⑮⑯⑰⑱⑲⑳ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ㍉㌔㌢㍍㌘㌧㌃㌶㍑㍗\"\n",
    "                   \"㌍㌦㌣㌫㍊㌻㎜㎝㎞㎎㎏㏄㎡㍻〝〟№㏍℡㊤㊥㊦㊧㊨㈱㈲㈹㍾㍽㍼∮\"\n",
    "                   \"∑∟⊿ⅰⅱⅲⅳⅴⅵⅶⅷⅸⅹ￤＇＂◇◎●○★☆§＠＊＆＃％￡￠＄\"\n",
    "                   \"￥℃″′°♀♂∴∞≧≦＞＜≠＝÷×±－＋】【』『」「》《〉〈｝\"\n",
    "                   \"｛］［〕〔）（”“’‘‥…｜∥～＼／‐―〆々仝〃ゞゝヾヽ＿￣＾\"\n",
    "                   \"¨｀´゜゛；：・，　╂┸┥┰┝┿┷┨┯┠╋┻┫┳┣┗\"\n",
    "                   \"┛┓┏┃━┼┴┤┬├└┘┐┌│─〇\"\n",
    "                   \"\\\"#$%&'()*+,-/:;<=>@[\\]^_`{|}~\")\n",
    "    sentence = ''.join(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', '', sentence)\n",
    "    sentence = re.sub(r'\\d+\\.*\\d*', '0', sentence)\n",
    "    sentence = neologdn.normalize(sentence)\n",
    "    sentence = unicodedata.normalize(\"NFKC\", sentence)\n",
    "    sentence = re.sub(\"[\" + symbols + \"]\", '', sentence)\n",
    "    return sentence\n",
    "\n",
    "def tokenizer_with_preprocessing(text, tokenizer=tokenizer.tokenize):\n",
    "    text = cleaning(text)\n",
    "    return tokenizer(text)\n",
    "\n",
    "def get_DataLoaders_and_TEXT(max_length, batch_size):\n",
    "    #テキストの前処理\n",
    "    TEXT = torchtext.data.Field(sequential=True, \n",
    "                                tokenize=tokenizer_with_preprocessing, \n",
    "                                use_vocab=True, \n",
    "                                include_lengths=True,\n",
    "                                batch_first=True,\n",
    "                                fix_length=max_length,\n",
    "                                init_token='[CLS]',\n",
    "                                eos_token='[SEP]',\n",
    "                                pad_token='[PAD]',\n",
    "                                unk_token='[UNK]',\n",
    "                                )\n",
    "    LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "    #data setの取得\n",
    "    train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
    "        path='./data/', \n",
    "        train='train.tsv',\n",
    "        validation='val.tsv',\n",
    "        test='test.tsv',\n",
    "        format='tsv',\n",
    "        skip_header=True,\n",
    "        fields=[('Text', TEXT), ('Label', LABEL)]\n",
    "    )\n",
    "\n",
    "    # ボキャブラリーの作成\n",
    "    # エラー回避のため一旦仮で作成し、bertのvocabで上書き\n",
    "    TEXT.build_vocab(train_ds, min_freq=1)\n",
    "    TEXT.vocab.stoi = tokenizer.vocab\n",
    "\n",
    "    # Data loaderの作成\n",
    "    train_dl = torchtext.data.Iterator(train_ds, batch_size=batch_size, train=True)\n",
    "    val_dl = torchtext.data.Iterator(val_ds, batch_size=batch_size, train=False, sort=False)\n",
    "    test_dl = torchtext.data.Iterator(test_ds, batch_size=batch_size, train=False, sort=False)\n",
    "\n",
    "    return train_dl, val_dl, test_dl, TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lseAvff1FJy"
   },
   "outputs": [],
   "source": [
    "# max_lengthは128安定、batchは適当でいい\n",
    "max_length=128\n",
    "batch_size=32\n",
    "train_dl, val_dl, test_dl, TEXT = get_DataLoaders_and_TEXT(\n",
    "    max_length=max_length,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloaders_dict = {\"train\":train_dl, \"val\": val_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMBRChQM1FJ9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xu5dqk2F1FKI"
   },
   "source": [
    "# BERTモデルへの入力例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176058,
     "status": "ok",
     "timestamp": 1581167671668,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "uVsx5wbV1FKM",
    "outputId": "68f2ff35-479b-41de-cf46-fcd1bd524b3f"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))\n",
    "inputs = batch.Text[0].to(device)  # 文章\n",
    "labels = batch.Label.to(device)  # ラベル\n",
    "print(inputs, labels)\n",
    "loss, logit = model(input_ids=inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJeBMfFH1FKi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVECzhlt1FKr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baK8apIg1FLB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USpcvv301FLK"
   },
   "source": [
    "# BERTを文書分類でFinetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jdCohxP1FLR"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    based on: https://github.com/Bjarten/early-stopping-pytorch\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xPwhdV61FLc"
   },
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, patience):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # ミニバッチのサイズ\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    # early stopping\n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "            iteration = 1\n",
    "\n",
    "            # 開始時刻を保存\n",
    "            t_epoch_start = time.time()\n",
    "            t_iter_start = time.time()\n",
    "            predictions = []\n",
    "            ground_truths = []\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書型変数\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch.Text[0].to(device)  # 文章\n",
    "                labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    loss, logit = net(input_ids=inputs, labels=labels)                    \n",
    "                    #loss = criterion(outputs, labels)  # 損失を計算\n",
    "                    _, preds = torch.max(logit, 1)  # ラベルを予測\n",
    "                    predictions.append(preds.cpu().numpy())\n",
    "                    ground_truths.append(labels.data.cpu().numpy())\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (iteration % 1 == 0):  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            acc = (torch.sum(preds == labels.data)\n",
    "                                ).double()/batch_size\n",
    "                            \n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                    iteration += 1\n",
    "\n",
    "                    # 損失と正解数の合計を更新\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            t_epoch_finish = time.time()\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "            ) / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                        phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val':\n",
    "                early_stopping(epoch_loss, net)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                # load the last checkpoint with the best model\n",
    "                net.load_state_dict(torch.load('checkpoint.pt'))\n",
    "                return net\n",
    "\n",
    "            t_epoch_start = time.time()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IUWEHDd1FLq"
   },
   "outputs": [],
   "source": [
    "def predict(net, test_dl):\n",
    "        # GPUが使えるかを確認\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        net.eval()\n",
    "        net.to(device)\n",
    "        logits = []\n",
    "        for batch in test_dl:\n",
    "            inputs = batch.Text[0].to(device)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                logit = net(input_ids=inputs)\n",
    "                logit = F.softmax(logit[0], dim=1).cpu().numpy()\n",
    "                logits.append(logit)\n",
    "        return np.concatenate(logits, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpfiFYEC1FL0"
   },
   "outputs": [],
   "source": [
    "def fit(net, dataset,  num_epochs, early_stopping_rounds=10, fine_tuning_type='fast'):\n",
    "    if fine_tuning_type == 'fast':\n",
    "        # 1. まず全部を、勾配計算Falseにしてしまう\n",
    "        for name, param in net.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        # 2. 最後のBertLayerモジュールを勾配計算ありに変更\n",
    "        for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
    "            param.requires_grad = True\n",
    "        # 3. 識別器を勾配計算ありに変更\n",
    "        for name, param in net.classifier.named_parameters():\n",
    "            param.requires_grad = True\n",
    "    elif fine_tuning_type == 'full':\n",
    "        for name, param in net.named_parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    optimizer = optim.Adam([\n",
    "                {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
    "                {'params': net.classifier.parameters(), 'lr': 5e-5}\n",
    "            ], betas=(0.9, 0.999))\n",
    "\n",
    "    # 損失関数の設定\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 学習・検証を実行する。\n",
    "    net = train_model(\n",
    "        net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs,\n",
    "        patience=early_stopping_rounds)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 174910,
     "status": "error",
     "timestamp": 1581167673477,
     "user": {
      "displayName": "Tomoya Hashiguchi",
      "photoUrl": "",
      "userId": "11920687669823389557"
     },
     "user_tz": -540
    },
    "id": "LL9r6MWo1FL8",
    "outputId": "0cf8ea1f-c5ee-4dae-e845-f2a75cec76a6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = fit(model, dataloaders_dict, num_epochs=100, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SR_OqOdy1FMF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xF4vHZ8t1FMM"
   },
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwjvG_xt1FMP"
   },
   "outputs": [],
   "source": [
    "y_proba = predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZzTAQtJ1FMX"
   },
   "outputs": [],
   "source": [
    "for batch, prob in zip(test_dl, y_proba):\n",
    "    true = batch.Label[0]\n",
    "    predict = np.argmax(prob)\n",
    "    print(true, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGfHpGrR1FMh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wT9A11Em1FMr"
   },
   "source": [
    "# モデルのsaveとload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alTiUIN71FMu"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('./classification_model/') # save\n",
    "model = BertForSequenceClassification.from_pretrained('./classification_model') # load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALFqYWDu1FM4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_classification_with_transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
